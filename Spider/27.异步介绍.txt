高性能异步爬虫：
目的：在爬虫中使用异步实现高性能的数据爬取操作

通常的，在正常我们通过编写代码对网页模拟发起请求或者一次性对多个网页发起请求并返回一些数据，但是执行的时候会发现，爬虫会一步一步的去执行，一个一个的去请求第一第二......的网址（会造成阻塞），这样的话就会极大的浪费时间，因此要寻找一种可以并行处理的结局方法———异步

异步爬虫的方式：
    -多线程 多进程：（不建议使用，后续有更好的方案去优化）
          优点：可以为相关阻塞的操作单独开启线程或者进程，阻塞操作就可以异步执行
          缺点：无法无限制的开启多线程或者多进程

    -线程池 进程池：（建议适当的使用）
         优点：我们可以降低系统对进程或者线程创建和销毁的一个频率，从而很好的降低系统的开销
         缺点：池中线程或进程的数量是有上限的—当超过了这个数量的时候效率反而会变低

建议将那些会造成阻塞导致很耗时的操作写成函数，然后用线程池来处理

代码展示：
    from multiprocessing.dummy import Pool

    def display():
        '''这里是阻塞效果函数'''
        ......
    urls

    #实例化一个线程对象
    pool = Pool(4)---里面的数字是表示处理堵塞的数量，例如我请求下载4次，就写入4
    #将封装的堵塞操作传入
    pool.map(display,urls)
    pool.close()